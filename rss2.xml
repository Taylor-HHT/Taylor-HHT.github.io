<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Welcome Taylor</title>
    <link>http://example.com/</link>
    
    <atom:link href="http://example.com/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>I want auroras and sad prose.</description>
    <pubDate>Mon, 03 Mar 2025 13:48:18 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>调研MSA中的方法（一）：Multi-view</title>
      <link>http://example.com/2025/03/03/%E8%B0%83%E7%A0%94MSA%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/</link>
      <guid>http://example.com/2025/03/03/%E8%B0%83%E7%A0%94MSA%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/</guid>
      <pubDate>Mon, 03 Mar 2025 13:43:06 GMT</pubDate>
      
      <description>&lt;p&gt;这一章介绍四篇MSA中经典的结合多视图方法的文章~预告本系列共四章：多视图、对抗学习、元学习、对比学习。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>这一章介绍四篇MSA中经典的结合多视图方法的文章~预告本系列共四章：多视图、对抗学习、元学习、对比学习。</p><span id="more"></span><h4 id="1-multi-view"><a href="#1-multi-view" class="headerlink" title="1. multi-view"></a>1. multi-view</h4><h5 id="（1）FACTORIZED-CONTRASTIVE-LEARNING-Going-Beyond-Multi-view-Redundancy-NeurIPS-2023"><a href="#（1）FACTORIZED-CONTRASTIVE-LEARNING-Going-Beyond-Multi-view-Redundancy-NeurIPS-2023" class="headerlink" title="（1）FACTORIZED CONTRASTIVE LEARNING: Going Beyond Multi-view Redundancy (NeurIPS 2023)"></a>（1）FACTORIZED CONTRASTIVE LEARNING: Going Beyond Multi-view Redundancy (NeurIPS 2023)</h5><p>&#x3D;&#x3D;标签：&#x3D;&#x3D;对比学习，重视unique information，</p><p>&#x3D;&#x3D;解决的问题：&#x3D;&#x3D;多视图学习有基础的假设“multi-view redundancy” ：模态之间贡献的信息都是与任务相关的。忽略了“多视图的非冗余和独特的信息可能是重要的”这种情况。</p><p>&#x3D;&#x3D;主要工作：&#x3D;&#x3D;</p><p><img src="F:/files/myBlog/images/image-20241012150724734.png" alt="image-20241012150724734"></p><p><img src="F:/files/myBlog/images/image-20241012150707918.png" alt="image-20241012150707918"></p><p>数据增强：</p><p><img src="F:/files/myBlog/images/image-20241012150748519.png" alt="image-20241012150748519"></p><p>&#x3D;&#x3D;可以改进的地方：&#x3D;&#x3D;①可以使用更好的MI上下界来优化目标，具体参考一些文献；</p><p>②目前的数据增强方法需要手动选择增强方式，以大致满足<strong>定义 4</strong> 中的要求。可以用其他方式替代：①<strong>自动生成数据增强</strong>：可以扩展 <strong>InfoMin</strong> 方法，使其能够自动生成数据增强策略，以更好地满足定义 4 的标准。这意味着，不再需要手动选择增强方法，而是可以通过算法自动决定哪些增强方式最有效。②利用未来的多模态生成模型。</p><p>③可以衡量shared 或unique information哪个信息对任务来说更重要，然后可以给优化目标函数的项赋不一样的权重值。</p><p>&#x3D;&#x3D;任务：&#x3D;&#x3D;包括医疗，MSA，sarcasm任务</p><p>&#x3D;&#x3D;数据集：&#x3D;&#x3D;MIMIC，MOSEI，MOSI，UR-FUNNY</p><p>&#x3D;&#x3D;结果：&#x3D;&#x3D;</p><p>&#x3D;&#x3D;代码：&#x3D;&#x3D;<a href="https://github.com/pliang279/FactorCL">https://github.com/pliang279/FactorCL</a>.</p><h5 id="（2）Gacs-Korner-Common-Information-Variational-Autoencoder-NeurIPS-2023"><a href="#（2）Gacs-Korner-Common-Information-Variational-Autoencoder-NeurIPS-2023" class="headerlink" title="（2）Gács-Körner Common Information Variational Autoencoder (NeurIPS 2023)"></a>（2）Gács-Körner Common Information Variational Autoencoder (NeurIPS 2023)</h5><p>&#x3D;&#x3D;标签：&#x3D;&#x3D;重视common information</p><p>&#x3D;&#x3D;解决的问题：&#x3D;&#x3D;假设用 (A, B, C) 来构造两个变量 X 和 Y，使$$X &#x3D; f(A, C)$$，$$Y &#x3D; g(B, C)$$，并且 C 编码了 X 和 Y 之间的所有且仅有的互信息 $$I(X; Y)$$，没有办法求得从高维数据中编码的这个最大公因数C。</p><p>&#x3D;&#x3D;主要工作：&#x3D;&#x3D;GK-VAE</p><p><img src="F:/files/myBlog/images/image-20241012151353797.png" alt="image-20241012151353797"></p><p>&#x3D;&#x3D;可以改进的地方：&#x3D;&#x3D;</p><p>&#x3D;&#x3D;任务：&#x3D;&#x3D;图像分类</p><p>&#x3D;&#x3D;数据集：&#x3D;&#x3D;3dshapes，dsprites</p><p><img src="F:/files/myBlog/images/image-20241012151540576.png" alt="image-20241012151540576"></p><p>&#x3D;&#x3D;结果：&#x3D;&#x3D;</p><p>&#x3D;&#x3D;代码：&#x3D;&#x3D;<a href="https://github.com/mjkleinman/common-vae">https://github.com/mjkleinman/common-vae</a></p><h5 id="（3）MISA-Modality-Invariant-and-Specific-Representations-for-Multimodal-Sentiment-Analysis-ACM-MM2020"><a href="#（3）MISA-Modality-Invariant-and-Specific-Representations-for-Multimodal-Sentiment-Analysis-ACM-MM2020" class="headerlink" title="（3）MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis (ACM MM2020)"></a>（3）MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis (ACM MM2020)</h5><p>&#x3D;&#x3D;标签：&#x3D;&#x3D;重视common和unique information</p><p>&#x3D;&#x3D;解决的问题：&#x3D;&#x3D;异构性导致的distributional modality gaps</p><p>&#x3D;&#x3D;主要工作：&#x3D;&#x3D;文章主要focus在如何有效地学习模态表示上，核心idea是将每个模态映射到两个不同的子 空间（factorized representations）。在第一个子空间中，学习模态间的共同信息（commonalities &#x2F;  common information）来减少模态间的差异。在第二个子空间中，学习每个模态私有的、特有的信 息。</p><p><img src="F:/files/myBlog/images/image-20241012151825928.png" alt="image-20241012151825928"></p><p>主要用了四个loss来学习模态表示：相似度通过内积计算</p><img src="F:/files/myBlog/images/image-20240511225739028.png" alt="image-20240511225739028" style="zoom:80%;" /><p>结合框架图来看，不同的loss起着各自的作用：</p><ul><li>Similarity Loss（$\mathcal{L}_{sim}$）：通过最小化相似性损失，减少每个模态的共享表示之间的差异，有助于将共同的跨模态特征对齐在一起。</li><li>Difference Loss（$\mathcal{L}_{diff}$）：通过施加软正交约束来确保模态不变和特定表示捕获输入的不同方面，同时还添加了模态特定向量之间的正交性约束。</li><li>Reconstruction Loss（$\mathcal{L}_{recon}$）：通过添加重构损失来确保潜在特征捕获其各自模态的细节，避免学习到无关紧要的表示。</li><li>Task Loss（$\mathcal{L}_{task}$）：用于评估训练时模型预测任务的准确性，对于分类任务使用标准的交叉熵损失，对于回归任务使用均方误差损失。</li></ul><p>&#x3D;&#x3D;可以改进的地方：&#x3D;&#x3D;没有量化共有信息和unique信息</p><p>&#x3D;&#x3D;任务：&#x3D;&#x3D;MSA，sarcasm</p><p>&#x3D;&#x3D;数据集：&#x3D;&#x3D;MOSI，MOSEI，FUNNY</p><p>&#x3D;&#x3D;结果：&#x3D;&#x3D;很一般</p><p><img src="F:/files/myBlog/images/image-20241012152356165.png" alt="image-20241012152356165"></p><p><img src="F:/files/myBlog/images/image-20241012152405408.png" alt="image-20241012152405408"></p><p>&#x3D;&#x3D;代码：&#x3D;&#x3D;<a href="https://github.com/declare-lab/MISA">https://github.com/declare-lab/MISA</a></p><h5 id="（4）Multi-View-Interactive-Representations-for-Multimodal-Sentiment-Analysis-IEEE-TRANSACTIONS-ON-CONSUMER-ELECTRONICS-2024"><a href="#（4）Multi-View-Interactive-Representations-for-Multimodal-Sentiment-Analysis-IEEE-TRANSACTIONS-ON-CONSUMER-ELECTRONICS-2024" class="headerlink" title="（4）Multi-View Interactive Representations for Multimodal Sentiment Analysis (IEEE TRANSACTIONS ON CONSUMER ELECTRONICS 2024)"></a>（4）Multi-View Interactive Representations for Multimodal Sentiment Analysis (IEEE TRANSACTIONS ON CONSUMER ELECTRONICS 2024)</h5><p>&#x3D;&#x3D;标签：&#x3D;&#x3D;自监督标签生成</p><p>&#x3D;&#x3D;解决的问题：&#x3D;&#x3D;现有的多模态情感分析方法在捕捉不同交互状态下的多视角情感线索方面存在不足，导致多模态表示的表达能力受限。本文提出了一个新框架（MVIR），通过在多种交互状态下学习共享和私有的情感信息，增强了情感分析的表现。</p><p>&#x3D;&#x3D;主要工作：&#x3D;&#x3D;<strong>MVIR框架</strong>：一个创新的多模态情感分析框架，利用多任务学习来捕捉不同交互状态下的多视角交互表示。</p><p><strong>DVAWF算法</strong>：设计了双视角注意力（多头图注意力网络和多头自注意力机制）加权融合机制，促进跨模态的交互，增强特征融合。</p><p><strong>SSLGM模块</strong>：引入自监督标签生成模块，为不同交互状态生成伪标签，进一步优化模型的情感表示能力。</p><p>&#x3D;&#x3D;可以改进的地方：&#x3D;&#x3D;</p><p>&#x3D;&#x3D;任务：&#x3D;&#x3D;MSA</p><p>&#x3D;&#x3D;数据集：&#x3D;&#x3D;MOSI, MOSEI, SIMS</p><p>&#x3D;&#x3D;结果：&#x3D;&#x3D;一般</p><p><img src="F:/files/myBlog/images/image-20241012163328960.png" alt="image-20241012163328960"></p><p>&#x3D;&#x3D;代码：&#x3D;&#x3D;无</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Papers/">Papers</category>
      
      
      <category domain="http://example.com/tags/MSA/">MSA</category>
      
      <category domain="http://example.com/tags/%E5%A4%9A%E8%A7%86%E5%9B%BE/">多视图</category>
      
      
      <comments>http://example.com/2025/03/03/%E8%B0%83%E7%A0%94MSA%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%80%EF%BC%89/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>论文阅读笔记：Divide, Conquer and Combine Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing</title>
      <link>http://example.com/2023/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0Divide-Conquer-and-Combine-Hierarchical-Feature-Fusion-Network-with-Local-and-Global-Perspectives-for-Multimodal-Affective-Computing/</link>
      <guid>http://example.com/2023/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0Divide-Conquer-and-Combine-Hierarchical-Feature-Fusion-Network-with-Local-and-Global-Perspectives-for-Multimodal-Affective-Computing/</guid>
      <pubDate>Sun, 08 Oct 2023 09:12:42 GMT</pubDate>
      
      <description>&lt;p&gt;方法的核心正如题目所说，设计了一个分层的融合网络，去学习局部和全局的信息，并且作者把这个流程定为了三个阶段：分治合——Divide，Conquer，Combine。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>方法的核心正如题目所说，设计了一个分层的融合网络，去学习局部和全局的信息，并且作者把这个流程定为了三个阶段：分治合——Divide，Conquer，Combine。</p><span id="more"></span><p>总体框架图如下：文本、图像、语音各自提取特征，在Divide阶段加入了一个滑动窗口，相当于把三个模态的特征进行了“切割”；再对切割后的小块局部特征进行外积操作（跟TFN模型一样的思想），外积就是在融合局部特征，是Conquer阶段；最后在Combine阶段设计了ABS-LSTM，用于提取全局特征。</p><p><img src="/images/image-20231007190803453.png" alt="image-20231007190803453"></p><p>接下来具体讲一下模型部分的某些细节，顺便讲一下论文提出的ABS-LSTM。</p><p>之所以ABS-LSTM能提取全局特征，是因为他特别注意前t个时间步的交互和信息，在当前输入的情况下，对前t个时间步给予权重得分。</p><p>第<code>L</code>步状态的cell和states计算如下：</p><p><img src="/images/image-20231007193954999.png" alt="image-20231007193954999"></p><p>接着就是LSTM的计算公式：</p><p><img src="/images/image-20231007194913954.png" alt="image-20231007194913954"></p><p>与传统的LSTM相比，h<del>l</del>和c<del>l</del>替换掉了h<del>l-1</del>和c<del>l-1</del>，传统的LSTM的对之前信息的融入通过上一步的h<del>l-1</del>和c张量，但ABS-LSTM对以前信息直接focus在前t个时间状态中，这样当前步对它们的关注更多。</p><p>同时为了防止之前的信息被稀释掉，在LSTM的hidden states计算中加入了Attention机制GIA：</p><p><img src="/images/image-20231007202145251.png" alt="image-20231007202145251"></p><p>w<del>h</del>和w<del>x</del>这两个参数蕴含了第l步隐藏向量和当前输入的重要性。所以在h<del>l</del>^a^的计算中，W<del>h2</del>w<del>h</del>作为权重，W<del>x2</del>w<del>x</del>作为bias，融入了这两个信息。</p><p>结果：</p><p><img src="/images/image-20231007204539523.png" alt="image-20231007204539523"></p><p>这还有一个小点，文章对滑动窗口的步长s和大小d进行了分析，发现当s大于d，也就是当有一些模态特征在融合阶段被遗留下来的时候，效果并没有很大的变化，这可以推测出模态特征有冗余的部分。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Papers/">Papers</category>
      
      
      <category domain="http://example.com/tags/Paper-Reading/">Paper Reading</category>
      
      <category domain="http://example.com/tags/MSA/">MSA</category>
      
      
      <comments>http://example.com/2023/10/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0Divide-Conquer-and-Combine-Hierarchical-Feature-Fusion-Network-with-Local-and-Global-Perspectives-for-Multimodal-Affective-Computing/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>论文阅读笔记：UniMSE:
Towards Unified Multimodal Sentiment Analysis and Emotion Recognition
</title>
      <link>http://example.com/2023/10/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0UniMSE-Towards-Unified-Multimodal-Sentiment-Analysis-and-Emotion-Recognition/</link>
      <guid>http://example.com/2023/10/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0UniMSE-Towards-Unified-Multimodal-Sentiment-Analysis-and-Emotion-Recognition/</guid>
      <pubDate>Sat, 07 Oct 2023 02:50:07 GMT</pubDate>
      
      <description>&lt;p&gt;这篇文章有效结合了多模态情感分析和情绪识别两种任务。&lt;/p&gt;
&lt;p&gt;发表出处：EMNLP 2022&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>这篇文章有效结合了多模态情感分析和情绪识别两种任务。</p><p>发表出处：EMNLP 2022</p><span id="more"></span><p><del>第一篇给老师汇报的论文，现在再写下笔记，有点把呕了的东西再吃下去的感觉:joy:</del></p><p>笔记从下面五部分讲解：</p><h3 id="Research-Background"><a href="#Research-Background" class="headerlink" title="Research Background"></a>Research Background</h3><p><img src="/images/image-20231007163658519.png" alt="image-20231007163658519"></p><ul><li>从心理认知角度来看，情感分析MSA和情绪识别ERC的人类表达方式是一样的，所以这两个任务在直觉上可以进行关联和互补，但是现研究针对这两个任务的研究一般都是独立的，没有把他们关联起来。</li><li>情感Sentiment和情绪Emotion的定义：前者持续时间长，预测极性标签（positive，1.6）；后者持续时间短，预测情绪类别（joy）</li><li>&#x3D;&#x3D;Figure 1这张图初步展示了情感和情绪可以共享一个统一的表示空间，具体来说是通过具有相同的情感标签的样例的相似度来确定统一的一个lable&#x3D;&#x3D;</li></ul><h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><p><img src="/images/image-20231007164203289.png" alt="image-20231007164203289"></p><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>这部分的讲解可以分为五大部分：Method-Overall Architecture，Method-Task Formalization，Method-Pre-trained Modality Fusion(PMF) ，<strong>Method-Inter-modality Contrastive Learning</strong> ，Method- Grounding UL to MSA and ERC</p><ol><li><strong>Method-Overall Architecture</strong></li></ol><p><img src="/images/image-20231007164416156.png" alt="image-20231007164416156"></p><p><img src="/images/image-20231007164437307.png" alt="image-20231007164437307"></p><p>&#x3D;&#x3D;Figure 2有几个注意的点：训练集是都用到了MSA和ERC 的数据集，通过UL Lable集合起来。然后融合部分引进了对比学习，对比学习的过程就是以锚点为参照，在特征空间中将锚点和它的正样本拉得更近，将锚点和负样本推得更远。而在这个模型中具体来说就是以文本模态（小紫）为锚点，在同一个样例中三种模态让他们的表示相近（即pull close），不同的样例的三种模态push far，所以说这里的正样例有1个，负样例有n个&#x3D;&#x3D;</p><ol start="2"><li><strong>Method-Task Formalization</strong></li></ol><p><img src="/images/image-20231007164806498.png" alt="image-20231007164806498"></p><p>语音模态：用librosa 将原始声音输入处理成数值序列向量，提取梅尔谱图作为音频特征。</p><p>视频模态：从每个片段中提取固定的T帧，并使用在VGGface 4和AFEW数据集上预训练(有监督)的effecientNet来获取视频特征。</p><p><img src="/images/image-20231007164821984.png" alt="image-20231007164821984"></p><p>&#x3D;&#x3D;这里要注意他为什么能将MSA和ERC样本按照情感极性分为积极、中性和消极样本集。（我当时困惑了好久，以为ERC的数据集的标签只有情绪类别，哪来的情感极性，但其实这里用到的ERC数据集是有情感极性的，MSA数据集没有情感标签。大概是这样，具体可以看看代码和数据集。</p><ol start="3"><li><strong>Method-Pre-trained Modality Fusion(PMF)</strong></li></ol><p><img src="/images/image-20231007164854172.png" alt="image-20231007164854172"></p><p>M<del>i</del>为经过LSTM后得到的模态表征</p><ol start="4"><li><strong>Method-Inter-modality Contrastive Learning</strong></li></ol><p><img src="/images/image-20231007164908541.png" alt="image-20231007164908541"></p><ol start="5"><li><strong>Method- Grounding UL to MSA and ERC</strong></li></ol><p><img src="/images/image-20231007164948129.png" alt="image-20231007164948129"></p><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><img src="/images/image-20231007165412671.png" alt="image-20231007165412671"></p><p>后两个数据集用ACC\WF1</p><p><img src="/images/image-20231007165435291.png" alt="image-20231007165435291"></p><p>效果嘎嘎好</p><p><img src="/images/image-20231007165449012.png" alt="image-20231007165449012"></p><p><img src="/images/image-20231007165500944.png" alt="image-20231007165500944"></p><h3 id="Conclusion-Limitations"><a href="#Conclusion-Limitations" class="headerlink" title="Conclusion&amp;Limitations"></a>Conclusion&amp;Limitations</h3><p><img src="/images/image-20231007165512816.png" alt="image-20231007165512816"></p><p><img src="/images/image-20231007165523868.png" alt="image-20231007165523868"></p><p>Limitation这里，样例相似度是通过计算文本模态的相似度得到的，没有用到其他模态，所以作者认为相似度这里还可以改进。</p><p>启发：特征的融合也许还可以改进，即这部分，主要还是用到拼接</p><p><img src="/images/image-20231007172822666.png" alt="image-20231007172822666"></p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Papers/">Papers</category>
      
      
      <category domain="http://example.com/tags/Paper-Reading/">Paper Reading</category>
      
      <category domain="http://example.com/tags/MSA/">MSA</category>
      
      <category domain="http://example.com/tags/Emotion-Recognition/">Emotion Recognition</category>
      
      
      <comments>http://example.com/2023/10/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0UniMSE-Towards-Unified-Multimodal-Sentiment-Analysis-and-Emotion-Recognition/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>实验室环境搭建</title>
      <link>http://example.com/2023/10/07/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <guid>http://example.com/2023/10/07/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <pubDate>Sat, 07 Oct 2023 02:23:21 GMT</pubDate>
      
      <description>&lt;p&gt;实验室配备了新的电脑，故此记录实验室环境的配置。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>实验室配备了新的电脑，故此记录实验室环境的配置。</p><span id="more"></span><h3 id="服务器连接"><a href="#服务器连接" class="headerlink" title="服务器连接"></a>服务器连接</h3><ol><li>创建服务器账号，需要先生成公钥（命令行生成</li><li>用mobaxterm连接服务器账号，填写好配置信息，连接成功<ul><li>这里出现一个问题，当时生成公钥配置了密码，一直permission denied（应该是设置权限问题，找Administrator</li></ul></li></ol><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>Anaconda+VSCode</p><p>选择原因：Anaconda内嵌了Python，而且可以管理环境；VSCode可以通过插件连接服务器（Pycharm要专业版收费:cry:</p><p>找了几个教程手把手操作，还在Anaconda分别新建了Pytorch和Tensorflow环境（注意cpu和gpu版本）。但是忘记保存下来了&#x3D;&#x3D;</p><h3 id="conda命令行"><a href="#conda命令行" class="headerlink" title="conda命令行"></a>conda命令行</h3><p><strong>创建虚拟环境</strong>：yida_cv是我虚拟环境的名字，你取什么名字都OK，最好能够标记好环境。<br><code>conda create -n yida_cv python=3.6 </code></p><p><strong>激活&#x2F;切换虚拟环境</strong><br><code>conda activate yida_cv</code></p><p><strong>退出并进入base环境</strong><br><code>conda deactivate </code></p><p><strong>查看已有的虚拟环境</strong><br><code>conda env list</code></p><p><strong>删除虚拟环境</strong><br><code>conda remove -n yida_cv --all</code></p><hr><p>参考更多命令行：<br><a href="https://blog.csdn.net/weixin_43312117/article/details/123431626">https://blog.csdn.net/weixin_43312117/article/details/123431626</a></p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Learning/">Learning</category>
      
      
      <category domain="http://example.com/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">环境搭建</category>
      
      
      <comments>http://example.com/2023/10/07/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>我的第一篇博客</title>
      <link>http://example.com/2023/10/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</link>
      <guid>http://example.com/2023/10/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</guid>
      <pubDate>Wed, 04 Oct 2023 16:09:47 GMT</pubDate>
      
      <description>&lt;p&gt;主要记录Linux命令~&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>主要记录Linux命令~</p><span id="more"></span><h2 id="第一篇blog"><a href="#第一篇blog" class="headerlink" title="第一篇blog"></a>第一篇blog</h2><p>主要参考🔗：<a href="https://zhuanlan.zhihu.com/p/102592286">从零开始搭建个人博客（超详细） - 知乎 (zhihu.com)</a></p><p>感谢！</p><h3 id="使用git"><a href="#使用git" class="headerlink" title="使用git"></a>使用git</h3><p>在Blog根目录下git bash 进入</p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>hexo s</td><td>server 写完博客可以先本地看看，再deploy</td></tr><tr><td>hexo clean</td><td>clean 不是每一次都需要执行</td></tr><tr><td>hexo g</td><td>generate</td></tr><tr><td>hexo d</td><td>deploy 部署</td></tr><tr><td>hexo new “My New Post”</td><td>新建Blog</td></tr></tbody></table><h3 id="使用Linux命令-vim用法"><a href="#使用Linux命令-vim用法" class="headerlink" title="使用Linux命令-vim用法"></a>使用Linux命令-vim用法</h3><p>在学习的过程中，发现有一些大佬用Linux读取文件写文件一顿操作猛如虎（respect，而我还只会打开文件资源管理器，</p><p>所以在此记录下一些关于文件的Linux命令的用法：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">##for example </span><br><span class="line">pwd       ##查看当前路径</span><br><span class="line">ls -l</span><br><span class="line">cd themes/</span><br><span class="line">cd ..     ##回到上层</span><br><span class="line">vim congfig.yml</span><br><span class="line"></span><br><span class="line">##输入内容</span><br><span class="line">i   ##insert，输入i后，即可修改文件内容</span><br><span class="line">exc    ##退回</span><br><span class="line"></span><br><span class="line">#保存，但不退出vi</span><br><span class="line">:w    ##注意：不可省略</span><br><span class="line"></span><br><span class="line">##保存并退出vi</span><br><span class="line">:wq</span><br><span class="line"></span><br><span class="line">##退出vi，但不保存更改 </span><br><span class="line">:q!</span><br><span class="line"></span><br><span class="line">##用其他文件名保存                        </span><br><span class="line">:w filename</span><br><span class="line"></span><br><span class="line">##在现有文件中保存并覆盖该文件    </span><br><span class="line">:w! filename</span><br><span class="line"></span><br><span class="line">##跳转</span><br><span class="line">shift + g  ## 到最后一行</span><br><span class="line">gg         ## 首行</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Learning/">Learning</category>
      
      
      <category domain="http://example.com/tags/Linux/">Linux</category>
      
      
      <comments>http://example.com/2023/10/05/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Markdown语法</title>
      <link>http://example.com/2023/09/11/markdown%E8%AF%AD%E6%B3%95/</link>
      <guid>http://example.com/2023/09/11/markdown%E8%AF%AD%E6%B3%95/</guid>
      <pubDate>Mon, 11 Sep 2023 01:39:06 GMT</pubDate>
      
      <description>&lt;p&gt;让我们来快乐学起来Markdown吧~&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>让我们来快乐学起来Markdown吧~</p><span id="more"></span><p>reference：<a href="https://markdown.com.cn/basic-syntax/%EF%BC%8C">https://markdown.com.cn/basic-syntax/，</a>&lt;【8分钟让你快速掌握Markdown】 <a href="https://www.bilibili.com/video/BV1JA411h7Gw/?share_source=copy_web&vd_source=2c2cbf463a2a283764f665e8407d50a4%3E">https://www.bilibili.com/video/BV1JA411h7Gw/?share_source=copy_web&amp;vd_source=2c2cbf463a2a283764f665e8407d50a4&gt;</a></p><h2 id="1-标题前加井号"><a href="#1-标题前加井号" class="headerlink" title="1. 标题前加井号"></a><strong>1. 标题前加井号</strong></h2><p><em>PS:有六级</em></p><h3 id="小标题"><a href="#小标题" class="headerlink" title="小标题"></a>小标题</h3><h4 id="小小标题"><a href="#小小标题" class="headerlink" title="小小标题"></a>小小标题</h4><h2 id="2-粗体是两星号，斜体是一星号，下划线，高亮，emoji"><a href="#2-粗体是两星号，斜体是一星号，下划线，高亮，emoji" class="headerlink" title="2. 粗体是两星号，斜体是一星号，下划线，高亮，emoji"></a><strong>2. 粗体是两星号，斜体是一星号，下划线</strong>，高亮，emoji</h2><p>这里是<strong>加粗</strong><br>这里是<em>斜体</em><br>既<em><strong>加粗又斜体</strong></em></p><p><u>下划线</u></p><p>&#x3D;&#x3D;高亮文字&#x3D;&#x3D;</p><p>:smile::joy:</p><h2 id="3-引用是大于号，嵌套是多个大于号"><a href="#3-引用是大于号，嵌套是多个大于号" class="headerlink" title="3. 引用是大于号，嵌套是多个大于号"></a><strong>3. 引用是大于号，嵌套是多个大于号</strong></h2><blockquote><p>引用</p><blockquote><p>引用嵌套</p></blockquote></blockquote><h2 id="4-有序列表用数字，无序列表用横杠，嵌套按tab"><a href="#4-有序列表用数字，无序列表用横杠，嵌套按tab" class="headerlink" title="4. 有序列表用数字，无序列表用横杠，嵌套按tab"></a><strong>4. 有序列表用数字，无序列表用横杠，嵌套按tab</strong></h2><ol><li>有序列表</li><li>有序列表2</li></ol><ul><li>无序列表</li><li>无序列表2<ul><li>嵌套</li></ul></li></ul><h2 id="5-图片链接用中括号和圆括号"><a href="#5-图片链接用中括号和圆括号" class="headerlink" title="5. 图片链接用中括号和圆括号"></a><strong>5. 图片链接用中括号和圆括号</strong></h2><ul><li>一张网络图片<img src="//alifei04.cfp.cn/creative/vcg/veer/1600water/veer-303764513.jpg" alt="pic, test_picture" title="来自veer.com"></li><li>这是一个链接 <a href="https://markdown.com.cn/">Markdown语法</a></li><li>引用链接 <a href="https://markdown.com.cn/" title="markdown官网">Markdown语法</a>, <a href="https://markdown.com.cn/" title="markdown官网">Markdown语法</a>, <a href="https://markdown.com.cn/" title="markdown官网">Markdown语法</a></li><li>请参考[标题1](#1. 标题前加井号)</li><li>本地照片 <img src="/../images/background.png" alt="background"></li></ul><h2 id="6-代码用反引号"><a href="#6-代码用反引号" class="headerlink" title="6. 代码用反引号"></a><strong>6. 代码用反引号</strong></h2><p>行内代码实例 <code>nano</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure><h2 id="7-数学公式用latex，上下标"><a href="#7-数学公式用latex，上下标" class="headerlink" title="7. 数学公式用latex，上下标"></a><strong>7. 数学公式用latex，上下标</strong></h2><p>$$<br>\frac[\partial f][\partial x]<br>$$</p><p>$\theta&#x3D;x^2$</p><p>H<del>2</del>O, X^2^</p><h2 id="8-转义符号"><a href="#8-转义符号" class="headerlink" title="8. 转义符号"></a><strong>8. 转义符号</strong></h2><p>在前面加转义符号\</p><h2 id="9-分隔符号是空一行加横线"><a href="#9-分隔符号是空一行加横线" class="headerlink" title="9. 分隔符号是空一行加横线"></a><strong>9. 分隔符号是空一行加横线</strong></h2><p>text1</p><hr><p>text2</p><hr><h2 id="10-任务列表用中括号"><a href="#10-任务列表用中括号" class="headerlink" title="10. 任务列表用中括号"></a><strong>10. 任务列表用中括号</strong></h2><p><em>PS:中括号里面和后面要空一格</em></p><ul><li><input checked="" disabled="" type="checkbox"> 事1</li><li><input disabled="" type="checkbox"> 事2</li></ul><h2 id="11-表格"><a href="#11-表格" class="headerlink" title="11. 表格"></a><strong>11. 表格</strong></h2><table><thead><tr><th align="left">name</th><th align="right">age</th><th align="center">grade</th></tr></thead><tbody><tr><td align="left">Taylor</td><td align="right">22</td><td align="center">98</td></tr><tr><td align="left">Mike</td><td align="right">22</td><td align="center">100</td></tr></tbody></table><h2 id="12-脚注"><a href="#12-脚注" class="headerlink" title="12.脚注"></a><strong>12.脚注</strong></h2><p>学习markdown[^markdown]<br>[^markdown]:一种网络笔记规范语言</p><h2 id="13-嵌入式代码"><a href="#13-嵌入式代码" class="headerlink" title="13.嵌入式代码"></a>13.嵌入式代码</h2><p>插入iframe即可</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Learning/">Learning</category>
      
      
      <category domain="http://example.com/tags/Markdown/">Markdown</category>
      
      <category domain="http://example.com/tags/%E8%AF%AD%E6%B3%95/">语法</category>
      
      <category domain="http://example.com/tags/%E6%95%99%E7%A8%8B/">教程</category>
      
      
      <comments>http://example.com/2023/09/11/markdown%E8%AF%AD%E6%B3%95/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hello World</title>
      <link>http://example.com/2023/09/06/hello-world/</link>
      <guid>http://example.com/2023/09/06/hello-world/</guid>
      <pubDate>Wed, 06 Sep 2023 15:00:02 GMT</pubDate>
      
      <description>&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><span id="more"></span><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/Hexo/">Hexo</category>
      
      
      <category domain="http://example.com/tags/Hexo/">Hexo</category>
      
      
      <comments>http://example.com/2023/09/06/hello-world/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
